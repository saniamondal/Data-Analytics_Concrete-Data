{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhJ3pZW8nflVxp4W8KTiIY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saniamondal/Data-Analytics_Concrete-Data/blob/main/GC_Data_Analytics_Sania.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA3HdTIrsmbv"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#For visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#sklearn libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Dataset **'Concrete Compressive Strength'**"
      ],
      "metadata": {
        "id": "asX-zvwc4_gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel('/Concrete_Data.xls')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uj-bUVvTuSHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning Dataset"
      ],
      "metadata": {
        "id": "GRUYoONb5Muo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking Intial Shape\n",
        "df.shape"
      ],
      "metadata": {
        "id": "DmLpJK_Ku6d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "#Shape after removing duplicates\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Q1iEH0zjvAdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking on Missing Values\n",
        "df.isnull().sum()\n",
        "\n",
        "#Dropping null values\n",
        "df = df.dropna()\n",
        "\n",
        "#Shape after removing Nulls\n",
        "df.shape"
      ],
      "metadata": {
        "id": "u7URlcaQy5ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "1.   Duplicated Rows have been dropped.\n",
        "2.   No missing data has been found.\n",
        "3.   Data is cleaned.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7Thn_FL1z1pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Splitting"
      ],
      "metadata": {
        "id": "QmL4TxcF4eUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Features and Target\n",
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1]\n",
        "\n",
        "#Training Dataset\n",
        "X_train,X_temp,y_train,y_temp=train_test_split(X,y,test_size=0.3,random_state=2)\n",
        "\n",
        "#Validation and testing Dataset\n",
        "X_val,X_test,y_val,y_test=train_test_split(X_temp,y_temp,test_size=0.5,random_state=2)"
      ],
      "metadata": {
        "id": "rIiHtAuFy5-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape ,X_test.shape ,X_val.shape"
      ],
      "metadata": {
        "id": "wSpURZlqy6KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is randomly separated in three datasets for training, validation and testing. Splitting is done twice in this case.\n",
        "Shapes of the training, validation and testing datasets have been shown."
      ],
      "metadata": {
        "id": "jINACCxz26dV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Visualization"
      ],
      "metadata": {
        "id": "BoyZuqLUUOvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation heatmap\n",
        "labels=['Cement','BFS','Fly Ash','Water','Superplasticizer','Coarse Aggregate','Fine Aggregate','Age','Concrete Strength']\n",
        "plt.figure(figsize=(6,3))\n",
        "sns.heatmap(df.corr(),annot=True, annot_kws={\"size\":7}, cmap=\"coolwarm\",xticklabels=labels,yticklabels=labels)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RKEFyzS92lEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "1.   Cement has a high proportional influence on the concrete strength.\n",
        "2.   Superplasticizer improves strength without adding extra water.\n",
        "3.   Water negatively affects the strength.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KqChyITpk6IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.histplot(y, kde=True)\n",
        "plt.title(\"Concrete Strength Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g2KMfykIYq5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight**\n",
        "1. Strength distribution slightly right-skewed"
      ],
      "metadata": {
        "id": "itDYhthQps0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scatter Plot for every component against Concrete Strength\n",
        "plot=sns.pairplot(df,y_vars=df.columns[-1],x_vars=df.columns[:-1],aspect=1.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oB2KQeZtbrD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "1.   Cement vs Strength shows upward trend but clearly not linear.\n",
        "2.   Water shows a negative influence.\n",
        "3. In Age, strength gain slows over time.\n",
        "\n"
      ],
      "metadata": {
        "id": "OGR-bO5omUA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms for all features\n",
        "df.hist(figsize=(17,10), bins=20)\n",
        "plt.suptitle(\"Feature Distributions\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g9umd2KFdk0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**\n",
        "\n",
        "1.   Cement has a wider spread and is slightly right skewed.\n",
        "2.   BFS, fly ash, superplatisizer, Age clearly has a higher     input in the right of the graphs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xroI6X1Ai_CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Target Variable Behavior\n",
        "plt.figure(figsize=(5,3))\n",
        "sns.boxplot(x=y)\n",
        "plt.title(\"Boxplot of Concrete Strength\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N5AAEze_i-jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight\n",
        "\n",
        "1. Few outliers after 75Mpa are visible.\n",
        "\n"
      ],
      "metadata": {
        "id": "mOVm6B8NnNwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(df['Concrete compressive strength(MPa, megapascals) ']>75).value_counts()"
      ],
      "metadata": {
        "id": "G8a3lbTZnsfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are very few strength values after 75, they can be considered as outliers."
      ],
      "metadata": {
        "id": "0JHg79eGpLiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdaBoost.R2 From Scratch"
      ],
      "metadata": {
        "id": "cnlyza_xp-j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns = X.columns.astype(str)"
      ],
      "metadata": {
        "id": "6dSfff617nwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaBoostR2Scratch:\n",
        "\n",
        "    def __init__(self, n_estimators=50, random_state=42):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.random_state = random_state\n",
        "        self.models = []\n",
        "        self.alphas = []\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        #Ensure stable dataframe\n",
        "        X = pd.DataFrame(X).copy()\n",
        "        X.columns = X.columns.astype(str)\n",
        "        X = X.reset_index(drop=True)\n",
        "\n",
        "        y = pd.Series(y).reset_index(drop=True)\n",
        "\n",
        "        n = X.shape[0]\n",
        "        weights = 1 / n\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "\n",
        "            #Train weak learner\n",
        "            model = DecisionTreeRegressor(max_depth=1)\n",
        "\n",
        "            model.fit(X, y, sample_weight=weights)\n",
        "            y_pred = model.predict(X)\n",
        "\n",
        "            #Compute normalized absolute error\n",
        "            error = np.abs(y - y_pred)\n",
        "            error_max = error.max()\n",
        "\n",
        "            if error_max == 0:\n",
        "                self.models.append(model)\n",
        "                self.alphas.append(1)\n",
        "                break\n",
        "\n",
        "            error = error / error_max\n",
        "            weighted_error = np.sum(weights * error)\n",
        "\n",
        "            #Skip bad learner\n",
        "            if weighted_error >= 0.5 or weighted_error == 0:\n",
        "                continue\n",
        "            alpha = np.log((1-weighted_error) / weighted_error)\n",
        "\n",
        "            #Update weights\n",
        "            weights = weights * np.exp(alpha * error)\n",
        "            weights /= weights.sum()\n",
        "\n",
        "            self.models.append(model)\n",
        "            self.alphas.append(alpha)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        X = pd.DataFrame(X).copy()\n",
        "        X.columns = X.columns.astype(str)\n",
        "\n",
        "        model_preds = np.array([m.predict(X) for m in self.models])\n",
        "        weights = np.array(self.alphas)\n",
        "\n",
        "        return np.average(model_preds, axis=0, weights=weights)\n"
      ],
      "metadata": {
        "id": "b6btN4KJ8xoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Best Number of Weak Learners (M)"
      ],
      "metadata": {
        "id": "9xx5TsJEzAmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M_values = [5,10,20,40,60,80,100,150,200]\n",
        "val_scores = []\n",
        "\n",
        "for M in M_values:\n",
        "    model = AdaBoostR2Scratch(n_estimators=M)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "    val_scores.append(r2_score(y_val, preds))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(M_values, val_scores, marker=\"o\")\n",
        "plt.xlabel(\"Number of Weak Learners\")\n",
        "plt.ylabel(\"Validation R²\")\n",
        "plt.title(\"Model Selection Curve\")\n",
        "plt.show()\n",
        "\n",
        "best_M = M_values[val_scores.index(max(val_scores))]\n",
        "print(\"Best M:\", best_M)\n"
      ],
      "metadata": {
        "id": "ABNpGJoI8Abu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Scratch Model Test Evaluation"
      ],
      "metadata": {
        "id": "yxieT2Vj_O8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = AdaBoostR2Scratch(n_estimators=best_M)\n",
        "final_model.fit(X_train.copy(), y_train.copy())\n",
        "\n",
        "test_preds = final_model.predict(X_test)\n",
        "\n",
        "print(\"Test R² (Scratch):\", r2_score(y_test, test_preds))\n",
        "\n",
        "# Scatter plot\n",
        "plt.figure()\n",
        "plt.scatter(y_test, test_preds)\n",
        "plt.xlabel(\"True Strength\")\n",
        "plt.ylabel(\"Predicted Strength\")\n",
        "plt.title(\"Scratch AdaBoost Predictions\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R2pZYwIm_OnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This evaluation of the scratch AdaBoost.R2 model on the test dataset indicates a strong performance and good generalization capability of the model.\n",
        "\n",
        "Here, the scatter plot shows the values follow a close y=x line hence the predictions are closely aligned with actual values."
      ],
      "metadata": {
        "id": "ACGcFu-s_8cp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Sklearn AdaBoostRegressor"
      ],
      "metadata": {
        "id": "TaZnaKzUAiKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sk_model = AdaBoostRegressor(estimator=DecisionTreeRegressor(max_depth=1), n_estimators=best_M, random_state=2)\n",
        "\n",
        "sk_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "T282Cyli-uYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Sklearn Model Evaluation"
      ],
      "metadata": {
        "id": "P5ss9iNyA_sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sk_pred = sk_model.predict(X_test)\n",
        "\n",
        "print(\"Test R² (sklearn):\", r2_score(y_test, sk_pred))\n",
        "\n",
        "#Scatter Plot\n",
        "plt.figure()\n",
        "plt.scatter(y_test, sk_pred)\n",
        "plt.xlabel(\"True Strength\")\n",
        "plt.ylabel(\"Predicted Strength\")\n",
        "plt.title(\"sklearn AdaBoost Predictions\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VqwNkJyIBJQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison between the scratch-implementation to that of sklearn\n"
      ],
      "metadata": {
        "id": "_ucOEwZXBjuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   The scratch model produces smoother predictions, while sklearn's model shows discrete prediction levels due to how boosting aggregates decision stumps.\n",
        "2.   The scratch implementation demonstrates more continuous approximation, whereas sklearn shows piecewise behavior typical of boosted trees.\n",
        "3. The scratch model extrapolates high-strength values more smoothly, while sklearn tends to saturate predictions at upper ranges.\n",
        "4. The sklearn implementation is more stable but less flexible, while the scratch model adapts more closely to individual samples."
      ],
      "metadata": {
        "id": "oitYdQwmCGAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thanks.\n"
      ],
      "metadata": {
        "id": "zG36GcuoH3_A"
      }
    }
  ]
}